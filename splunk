cat output.json | jq -c '.[] | {event: ., sourcetype: "your_sourcetype", index: "your_index"}' | \
=================================================================
curl -v -k https://<splunk-host>:8088/services/collector/event \
  -H "Authorization: Splunk <SPLUNK_HEC_TOKEN>" \
  -H "Content-Type: application/json" \
  -d @<(echo "{\"event\": \"$(sed 's/"/\\"/g' report.html | sed ':a;N;$!ba;s/\n/ /g')\", \"sourcetype\": \"custom_html\", \"index\": \"main\"}")

index=main sourcetype=custom_html | sort -_time desc | table _time, _raw
------------------------
NEW MIGHT WORK CURL

HEC_URL="https://your-splunk-server:8088/services/collector/event"
HEC_TOKEN="YOUR_SPLUNK_HEC_TOKEN"

cat output.json | jq -c '.[] | {event: ., sourcetype: "your_sourcetype", index: "your_index"}' | \
while read payload; do
  curl -k -X POST "$HEC_URL" \
    -H "Authorization: Splunk $HEC_TOKEN" \
    -H "Content-Type: application/json" \
    -d

------------------------
PYTHON
import json

# Read your HTML file
with open('your_file.html', 'r', encoding='utf-8') as f:
    html_content = f.read()

# Prepare JSON payload
payload = {
    "event": html_content,
    "sourcetype": "custom_html",
    "index": "main"
}

# Convert to JSON string (escaped)
json_data = json.dumps(payload)

print(json_data)  # You can save or send this string to Splunk

---------------------------
import json
import re

def parse_html_table(html):
    # Extract all rows between <tr>...</tr>
    rows = re.findall(r'<tr>(.*?)</tr>', html, re.DOTALL)
    if not rows:
        return []

    # Extract header columns
    headers = re.findall(r'<th>(.*?)</th>', rows[0], re.DOTALL)
    headers = [h.strip() for h in headers]

    data = []
    # Process data rows (skip header)
    for row_html in rows[1:]:
        cols = re.findall(r'<td>(.*?)</td>', row_html, re.DOTALL)
        cols = [c.strip() for c in cols]
        if len(cols) == len(headers):
            entry = dict(zip(headers, cols))
            data.append(entry)
    return data

# Read your HTML file
with open('your_file.html', 'r', encoding='utf-8') as f:
    html_content = f.read()

table_data = parse_html_table(html_content)

# Output JSON
with open('output.json', 'w', encoding='utf-8') as f:
    json.dump(table_data, f, indent=2)

print("JSON saved to output.json")


---------------------------
Handling Python with more complex html where the above is for simple Sample.html

import json
import re

def parse_html_table(html):
    # Find the first <table ...> ... </table>
    table_match = re.search(r'<table[^>]*>(.*?)</table>', html, re.DOTALL | re.IGNORECASE)
    if not table_match:
        print("No table found")
        return []

    table_html = table_match.group(1)

    # Extract all rows between <tr ...>...</tr> (ignore attributes inside tr)
    rows = re.findall(r'<tr[^>]*>(.*?)</tr>', table_html, re.DOTALL | re.IGNORECASE)
    if not rows:
        print("No rows found in table")
        return []

    # Extract header columns from first row
    headers = re.findall(r'<th[^>]*>(.*?)</th>', rows[0], re.DOTALL | re.IGNORECASE)
    headers = [re.sub(r'<.*?>', '', h).strip() for h in headers]  # strip inner tags if any

    data = []
    # Process each data row (skip header)
    for row_html in rows[1:]:
        # Extract all <td> contents, ignoring tags inside td
        cols = re.findall(r'<td[^>]*>(.*?)</td>', row_html, re.DOTALL | re.IGNORECASE)
        cols = [re.sub(r'<.*?>', '', c).strip() for c in cols]

        if len(cols) == len(headers):
            entry = dict(zip(headers, cols))
            data.append(entry)
        else:
            print("Skipping a row due to column mismatch")

    return data

# Read your HTML file
with open('your_file.html', 'r', encoding='utf-8') as f:
    html_content = f.read()

table_data = parse_html_table(html_content)

# Output JSON
with open('output.json', 'w', encoding='utf-8') as f:
    json.dump(table_data, f, indent=2)

print("Parsed JSON saved to output.json")

